{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone project, Part 2\n",
    "for Zoomcamp, Ahmed Yahia Kallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuation of the notebook, with focus on the neural networks. \n",
    "\n",
    "So far, these are the best output\n",
    "* GB-lr003nest1000\n",
    "* training accuracy: 0.494942\n",
    "* validation accuracy: 0.544177"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train.py (part of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# libarires\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#splitter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#transformers\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "\n",
    "\n",
    "#model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#save pickle\n",
    "import pickle\n",
    "\n",
    "#read database\n",
    "df = pd.read_csv(\"Property Prices in Tunisia.csv\") #load file\n",
    "\n",
    "#translation\n",
    "df.replace(df[\"category\"].unique(), ['Land and Farms', 'Apartments', 'Holiday rentals',\n",
    "       'Shops, Businesses and Industrial Premises', 'Houses and Villas',\n",
    "       'Flatshare', 'Offices and Trays'],inplace=True)\n",
    "\n",
    "df.replace(df[\"type\"].unique(), ['For sale', 'For rent'],inplace=True)\n",
    "\n",
    "df.replace(\"Autres villes\",\"Others\", inplace=True)\n",
    "\n",
    "del df[\"price\"] \n",
    "\n",
    "\n",
    "# data splitting\n",
    "\n",
    "#split according to random state = 1\n",
    "df_trainval, df_test = train_test_split(df, test_size=0.2, random_state=1) #split train+val [80%], test [20%]\n",
    "df_train, df_val = train_test_split(df_trainval, test_size=0.25, random_state=1) #split train[60%] val [20%]\n",
    "\n",
    "#reset, drop index\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "\n",
    "y_test = df_test[\"log_price\"].values\n",
    "y_train = df_train[\"log_price\"].values\n",
    "y_val = df_val[\"log_price\"].values\n",
    "\n",
    "del df_test[\"log_price\"]\n",
    "del df_train[\"log_price\"]\n",
    "del df_val[\"log_price\"]\n",
    "\n",
    "\n",
    "\n",
    "# feature types\n",
    "feat_cat = ['category','type','city','region']\n",
    "feat_num = ['room_count','bathroom_count','size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = [\n",
    "    ('Scal_num', RobustScaler() , feat_num),\n",
    "    ('categorical', OneHotEncoder(dtype=np.int32,handle_unknown = 'ignore'), feat_cat)\n",
    "]\n",
    "transf = ColumnTransformer(transformations, remainder='drop')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special NN Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No bias, no extra layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/1675294560.py:7: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model )\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(273,use_bias=False))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "kr = KerasRegressor(build_fn=build_model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 925us/step - loss: 2.0109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('transformer',\n",
       "                 ColumnTransformer(transformers=[('Scal_num', RobustScaler(),\n",
       "                                                  ['room_count',\n",
       "                                                   'bathroom_count', 'size']),\n",
       "                                                 ('categorical',\n",
       "                                                  OneHotEncoder(dtype=<class 'numpy.int32'>,\n",
       "                                                                handle_unknown='ignore'),\n",
       "                                                  ['category', 'type', 'city',\n",
       "                                                   'region'])])),\n",
       "                ('nn',\n",
       "                 <keras.wrappers.scikit_learn.KerasRegressor object at 0x00000167378EB340>)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('nn', kr)\n",
    "])\n",
    "pipeline.fit(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.548\n",
      "Validation loss: 0.566\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2))\n",
    "print('Training loss: %2.3f' % rms(y_train- pipeline.predict(df_train)))\n",
    "print('Validation loss: %2.3f' % rms(y_val- pipeline.predict(df_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/2286808003.py:7: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model, epochs=10, batch_size=100 )\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_1/dense_2/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 2ms/step - loss: 4.9103\n",
      "Epoch 2/10\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4004\n",
      "Epoch 3/10\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2994\n",
      "Epoch 4/10\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2916\n",
      "Epoch 5/10\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2892\n",
      "Epoch 6/10\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2868\n",
      "Epoch 7/10\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2860\n",
      "Epoch 8/10\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2863\n",
      "Epoch 9/10\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2865\n",
      "Epoch 10/10\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2861\n",
      "Training loss: 0.526\n",
      "Validation loss: 0.563\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(273,use_bias=True))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "kr = KerasRegressor(build_fn=build_model, epochs=10, batch_size=100 )\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('nn', kr)\n",
    "])\n",
    "pipeline.fit(df_train, y_train)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2))\n",
    "print('Training loss: %2.3f' % rms(y_train- pipeline.predict(df_train)))\n",
    "print('Validation loss: %2.3f' % rms(y_val- pipeline.predict(df_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double input & bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/1217633080.py:7: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model )\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Reshape:0\", shape=(None, 546), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_2/dense_4/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239/239 [==============================] - 1s 1ms/step - loss: 1.4035\n",
      "Training loss: 0.542\n",
      "Validation loss: 0.567\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(273*2,use_bias=True))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "kr = KerasRegressor(build_fn=build_model )\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('nn', kr)\n",
    "])\n",
    "\n",
    "pipeline.fit(df_train, y_train)\n",
    "\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2))\n",
    "print('Training loss: %2.3f' % rms(y_train- pipeline.predict(df_train)))\n",
    "print('Validation loss: %2.3f' % rms(y_val- pipeline.predict(df_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Extra layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/1845786985.py:8: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_3/dense_6/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_3/dense_6/embedding_lookup_sparse/Reshape:0\", shape=(None, 546), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_3/dense_6/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 20ms/step - loss: 7.2015\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.6642\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.9851\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5430\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.3986\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.3213\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.2945\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.2872\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.2827\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.2799\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.2767\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.2770\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.2762\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.2777\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.2776\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.2772\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.2764\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.2772\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.2782\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.2763\n",
      "Training loss: 0.523\n",
      "Validation loss: 0.560\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(273*2,use_bias=True))\n",
    "    model.add(layers.Dense(272*2,use_bias=False))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('nn', kr)\n",
    "])\n",
    "pipeline.fit(df_train, y_train)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2))\n",
    "print('Training loss: %2.3f' % rms(y_train- pipeline.predict(df_train)))\n",
    "print('Validation loss: %2.3f' % rms(y_val- pipeline.predict(df_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/1518195368.py:9: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_4/dense_9/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_4/dense_9/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_4/dense_9/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 17ms/step - loss: 10.1109\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 2.2800\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8676\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6779\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5526\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4589\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4115\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3983\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.3905\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3777\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3758\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3789\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3710\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3719\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3635\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3717\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3635\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3661\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.3587\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3586\n",
      "Training loss: 0.525\n",
      "Validation loss: 0.560\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(273,use_bias=True))\n",
    "    model.add(layers.Dropout(.2))\n",
    "    model.add(layers.Dense(272*2,use_bias=False))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('nn', kr)\n",
    "])\n",
    "pipeline.fit(df_train, y_train)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2))\n",
    "print('Training loss: %2.3f' % rms(y_train- pipeline.predict(df_train)))\n",
    "print('Validation loss: %2.3f' % rms(y_val- pipeline.predict(df_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Different dropout linear/dropout/linear/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/2810878026.py:11: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_5/dense_12/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_5/dense_12/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_5/dense_12/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 10.8182\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.0232\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9202\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7568\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4504\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3832\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3699\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3381\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3322\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3307\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3276\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3273\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3201\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3210\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3237\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3165\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3188\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3161\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.3152\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3222\n",
      "Dropout: 0.100\n",
      "-- Training loss: 0.524\n",
      "-- Validation loss: 0.560\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/2810878026.py:11: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_6/dense_15/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_6/dense_15/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_6/dense_15/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 11ms/step - loss: 12.6416\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.9020\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.2059\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.9280\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5136\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4612\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4236\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3871\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3742\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3822\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3664\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3715\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3626\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3580\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3598\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3604\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.3540\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3567\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.3544\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3514\n",
      "Dropout: 0.189\n",
      "-- Training loss: 0.524\n",
      "-- Validation loss: 0.557\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/2810878026.py:11: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_7/dense_18/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_7/dense_18/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_7/dense_18/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 15ms/step - loss: 11.3759\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.1242\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.0356\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9214\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5762\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5004\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4713\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4401\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.4428\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4250\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4093\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4074\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4041\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3970\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3999\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.3947\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4085\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3988\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.3999\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3830\n",
      "Dropout: 0.278\n",
      "-- Training loss: 0.526\n",
      "-- Validation loss: 0.561\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/2810878026.py:11: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_8/dense_21/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_8/dense_21/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_8/dense_21/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 16ms/step - loss: 11.3920\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 2.2473\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.0579\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.9849\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.6469\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.5535\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.5569\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.5175\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4850\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4768\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4771\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4693\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4585\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4663\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.4422\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4390\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4410\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4293\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4332\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4369\n",
      "Dropout: 0.367\n",
      "-- Training loss: 0.527\n",
      "-- Validation loss: 0.559\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/2810878026.py:11: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_9/dense_24/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_9/dense_24/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_9/dense_24/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 15ms/step - loss: 11.2275\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 2.1143\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.1620\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 1.0443\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7459\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6324\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6256\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6046\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5567\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5632\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5285\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5184\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5214\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5109\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5009\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5035\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4765\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4847\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4694\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4636\n",
      "Dropout: 0.456\n",
      "-- Training loss: 0.528\n",
      "-- Validation loss: 0.559\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/2810878026.py:11: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_10/dense_27/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_10/dense_27/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_10/dense_27/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 18ms/step - loss: 11.0256\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.1900\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.2343\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.1855\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8555\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7606\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7057\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6870\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6634\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6643\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6230\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5975\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.5920\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.5877\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5890\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.5534\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5545\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5501\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5257\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5438\n",
      "Dropout: 0.544\n",
      "-- Training loss: 0.528\n",
      "-- Validation loss: 0.561\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/2810878026.py:11: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_11/dense_30/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_11/dense_30/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_11/dense_30/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 16ms/step - loss: 11.7995\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 2.4497\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.5304\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.3506\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9956\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8917\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8683\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7832\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7489\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7635\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7139\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7090\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6850\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6584\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6700\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.6484\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6275\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5998\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6105\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5986\n",
      "Dropout: 0.633\n",
      "-- Training loss: 0.532\n",
      "-- Validation loss: 0.560\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/2810878026.py:11: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_12/dense_33/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_12/dense_33/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_12/dense_33/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 12.7318\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.7571\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.9754\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.6920\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.2406\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.1553\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0800\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9629\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9609\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8975\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8630\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.8329\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7952\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7828\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.7866\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7487\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7522\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.7201\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.7270\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.7050\n",
      "Dropout: 0.722\n",
      "-- Training loss: 0.532\n",
      "-- Validation loss: 0.559\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/2810878026.py:11: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_13/dense_36/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_13/dense_36/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_13/dense_36/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 12.0295\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 3.1503\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.4273\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 2.1890\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.6310\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4526\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.3656\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.2908\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.2072\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.1374\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.1240\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0596\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.0307\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0146\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9831\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.9453\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.9067\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.8990\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9050\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.8654\n",
      "Dropout: 0.811\n",
      "-- Training loss: 0.542\n",
      "-- Validation loss: 0.563\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/2810878026.py:11: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_14/dense_39/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_14/dense_39/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_14/dense_39/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 20ms/step - loss: 12.6470\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 4.6371\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 3.6250\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 3.1007\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.4176\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 2.1899\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.0201\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.8786\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.7601\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.6811\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 1.6449\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.5666\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.4702\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.4852\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.4554\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.3651\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.3656\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.3533\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.3511\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.2687\n",
      "Dropout: 0.900\n",
      "-- Training loss: 0.556\n",
      "-- Validation loss: 0.573\n"
     ]
    }
   ],
   "source": [
    "for dropout in np.linspace(0.1,0.9,10):\n",
    "\n",
    "    def build_model():\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Dense(273,use_bias=True))\n",
    "        model.add(layers.Dropout(dropout))\n",
    "        model.add(layers.Dense(272,use_bias=False))\n",
    "        model.add(layers.Dense(1))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        return model\n",
    "    kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('transformer', transf),\n",
    "        ('nn', kr)\n",
    "    ])\n",
    "    pipeline.fit(df_train, y_train)\n",
    "\n",
    "    def rms(x):\n",
    "        return np.sqrt(np.mean(x**2))\n",
    "    print('Dropout: %2.3f' % dropout)\n",
    "    print('-- Training loss: %2.3f' % rms(y_train- pipeline.predict(df_train)))\n",
    "    print('-- Validation loss: %2.3f' % rms(y_val- pipeline.predict(df_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear/dropout/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/4259746530.py:10: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_15/dense_42/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_15/dense_42/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_15/dense_42/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 11ms/step - loss: 17.7313\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 10.9926\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 5.9841\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 2.8772\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.6529\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.3754\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.1245\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8514\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.6804\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5774\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4978\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4400\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3951\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3675\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3450\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3312\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3190\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3150\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3075\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3055\n",
      "Dropout: 0.100\n",
      "-- Training loss: 0.534\n",
      "-- Validation loss: 0.564\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/4259746530.py:10: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_16/dense_44/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_16/dense_44/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_16/dense_44/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 10ms/step - loss: 16.9600\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 10.1329\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 5.1330\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.2806\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 1.3486\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2209\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9702\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.7276\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6064\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5267\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.4618\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4124\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3856\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3634\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3454\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3372\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3306\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3176\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3186\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3179\n",
      "Dropout: 0.144\n",
      "-- Training loss: 0.533\n",
      "-- Validation loss: 0.562\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/4259746530.py:10: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_17/dense_46/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_17/dense_46/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_17/dense_46/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 18.6149\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 11.6093\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 6.3393\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 3.0766\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.7467\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.4441\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.2122\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.9175\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7321\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6182\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5282\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4696\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4244\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3950\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3693\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3579\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3464\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3412\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3390\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3309\n",
      "Dropout: 0.189\n",
      "-- Training loss: 0.537\n",
      "-- Validation loss: 0.566\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/4259746530.py:10: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_18/dense_48/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_18/dense_48/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_18/dense_48/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 9ms/step - loss: 16.0812\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 9.5182\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 4.8378\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.2559\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 1.4977\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 1.2942\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0149\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7619\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6372\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5529\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4705\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4333\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3967\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3861\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3582\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3575\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3434\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3449\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3423\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3396\n",
      "Dropout: 0.233\n",
      "-- Training loss: 0.533\n",
      "-- Validation loss: 0.562\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/4259746530.py:10: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_19/dense_50/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_19/dense_50/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_19/dense_50/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 8ms/step - loss: 16.6033\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 9.9591\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.1017\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.3289\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.4289\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.2430\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.0017\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7508\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.6171\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5501\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.4679\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4266\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3988\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3898\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.3663\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3668\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3640\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3513\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.3476\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3460\n",
      "Dropout: 0.278\n",
      "-- Training loss: 0.532\n",
      "-- Validation loss: 0.561\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/4259746530.py:10: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_20/dense_52/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_20/dense_52/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_20/dense_52/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 15ms/step - loss: 18.3599\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 11.1489\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 5.8350\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.6657\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.4819\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.3193\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0918\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.8381\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6876\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5985\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5187\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4708\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4434\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4222\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4039\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3823\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3780\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3818\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3769\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3607\n",
      "Dropout: 0.322\n",
      "-- Training loss: 0.534\n",
      "-- Validation loss: 0.564\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/4259746530.py:10: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_21/dense_54/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_21/dense_54/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_21/dense_54/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 11ms/step - loss: 17.9903\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 10.9253\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.7368\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.6908\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.6396\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 1.3948\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.1508\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8652\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7208\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6175\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5445\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4948\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4625\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4364\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4073\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4077\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4036\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3847\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.3794\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3720\n",
      "Dropout: 0.367\n",
      "-- Training loss: 0.533\n",
      "-- Validation loss: 0.563\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/4259746530.py:10: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_22/dense_56/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_22/dense_56/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_22/dense_56/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 10ms/step - loss: 17.2409\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 10.2535\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.2689\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.5079\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.6819\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.4814\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.1883\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9128\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.7387\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6613\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5754\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.5077\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4803\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4545\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.4342\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4286\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4148\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4120\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4091\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3974\n",
      "Dropout: 0.411\n",
      "-- Training loss: 0.538\n",
      "-- Validation loss: 0.565\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/4259746530.py:10: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_23/dense_58/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_23/dense_58/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_23/dense_58/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 11ms/step - loss: 18.2257\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 11.1306\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 5.9112\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.7587\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 1.6005\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 1.3830\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.1779\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.9036\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7511\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.6395\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5899\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5437\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4985\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4717\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4589\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4481\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4417\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4341\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.4190\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4292\n",
      "Dropout: 0.456\n",
      "-- Training loss: 0.535\n",
      "-- Validation loss: 0.565\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/4259746530.py:10: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_24/dense_60/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_24/dense_60/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_24/dense_60/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 10ms/step - loss: 17.9677\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 11.2851\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 6.2278\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 3.1133\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 1.8194\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.5280\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.3145\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.9884\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.8266\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.7294\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.6450\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 0.5813\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.5405\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5126\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4896\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4705\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4675\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4553\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4433\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.4447\n",
      "Dropout: 0.500\n",
      "-- Training loss: 0.536\n",
      "-- Validation loss: 0.564\n"
     ]
    }
   ],
   "source": [
    "for dropout in np.linspace(0.1,0.5,10):\n",
    "\n",
    "    def build_model():\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Dense(273,use_bias=True))\n",
    "        model.add(layers.Dropout(dropout))\n",
    "        model.add(layers.Dense(1))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        return model\n",
    "    kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('transformer', transf),\n",
    "        ('nn', kr)\n",
    "    ])\n",
    "    pipeline.fit(df_train, y_train)\n",
    "\n",
    "    def rms(x):\n",
    "        return np.sqrt(np.mean(x**2))\n",
    "    print('Dropout: %2.3f' % dropout)\n",
    "    print('-- Training loss: %2.3f' % rms(y_train- pipeline.predict(df_train)))\n",
    "    print('-- Validation loss: %2.3f' % rms(y_val- pipeline.predict(df_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with dropout, 3 inner layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/4248957711.py:12: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_25/dense_62/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_25/dense_62/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_25/dense_62/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 14ms/step - loss: 11.2854\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 2.2111\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8899\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5952\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4957\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4074\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3583\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3357\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3301\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3263\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.3198\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3207\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3201\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3224\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.3189\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3200\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3165\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.3196\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3121\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.3194\n",
      "Dropout: 0.100\n",
      "-- Training loss: 0.524\n",
      "-- Validation loss: 0.560\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/4248957711.py:12: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_26/dense_66/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_26/dense_66/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_26/dense_66/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 11.5121\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 2.0781\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.9179\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6992\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5299\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4387\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4137\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3915\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3630\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3613\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3591\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3621\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3562\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3598\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3551\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3585\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3590\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.3572\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3490\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3475\n",
      "Dropout: 0.200\n",
      "-- Training loss: 0.525\n",
      "-- Validation loss: 0.559\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/4248957711.py:12: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_27/dense_70/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_27/dense_70/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_27/dense_70/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 11.2263\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 2.1243\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.9512\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.7274\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.5897\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.4872\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4504\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4464\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4218\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4211\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4137\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4064\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4077\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.3962\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.4046\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3976\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3897\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3949\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3790\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3877\n",
      "Dropout: 0.300\n",
      "-- Training loss: 0.527\n",
      "-- Validation loss: 0.559\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/4248957711.py:12: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_28/dense_74/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_28/dense_74/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_28/dense_74/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 11ms/step - loss: 10.6612\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 2.2740\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 1.0496\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.7884\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.6845\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5753\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5484\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.5099\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.5033\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5000\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4819\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4756\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.4773\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4498\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4463\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4351\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4451\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.4305\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4318\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4207\n",
      "Dropout: 0.400\n",
      "-- Training loss: 0.526\n",
      "-- Validation loss: 0.561\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/4248957711.py:12: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_29/dense_78/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_29/dense_78/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_29/dense_78/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 12.2982\n",
      "Epoch 2/20\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 2.4713\n",
      "Epoch 3/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.2100\n",
      "Epoch 4/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1.0240\n",
      "Epoch 5/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.8235\n",
      "Epoch 6/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.6800\n",
      "Epoch 7/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.6597\n",
      "Epoch 8/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5929\n",
      "Epoch 9/20\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.5884\n",
      "Epoch 10/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5707\n",
      "Epoch 11/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.5505\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5384\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5195\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 0.5205\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.5096\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4870\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 0.4982\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4773\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4790\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.4734\n",
      "Dropout: 0.500\n",
      "-- Training loss: 0.531\n",
      "-- Validation loss: 0.563\n"
     ]
    }
   ],
   "source": [
    "for dropout in np.linspace(0.1,0.5,5):\n",
    "\n",
    "    def build_model():\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Dense(273,use_bias=True))\n",
    "        model.add(layers.Dropout(dropout))\n",
    "        model.add(layers.Dense(136,use_bias=True))\n",
    "        model.add(layers.Dense(68,use_bias=True))\n",
    "        model.add(layers.Dense(1))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        return model\n",
    "    kr = KerasRegressor(build_fn=build_model,epochs=20,batch_size=1000)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('transformer', transf),\n",
    "        ('nn', kr)\n",
    "    ])\n",
    "    pipeline.fit(df_train, y_train)\n",
    "\n",
    "    def rms(x):\n",
    "        return np.sqrt(np.mean(x**2))\n",
    "    print('Dropout: %2.3f' % dropout)\n",
    "    print('-- Training loss: %2.3f' % rms(y_train- pipeline.predict(df_train)))\n",
    "    print('-- Validation loss: %2.3f' % rms(y_val- pipeline.predict(df_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/1329411624.py:9: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=100,batch_size=100)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_30/dense_82/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_30/dense_82/embedding_lookup_sparse/Reshape:0\", shape=(None, 273), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_30/dense_82/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 1s 3ms/step - loss: 4.1793\n",
      "Epoch 2/100\n",
      "77/77 [==============================] - 1s 6ms/step - loss: 0.8804\n",
      "Epoch 3/100\n",
      "77/77 [==============================] - 0s 5ms/step - loss: 0.7121\n",
      "Epoch 4/100\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6719\n",
      "Epoch 5/100\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.6247\n",
      "Epoch 6/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5912\n",
      "Epoch 7/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5749\n",
      "Epoch 8/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5754\n",
      "Epoch 9/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5320\n",
      "Epoch 10/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.5023\n",
      "Epoch 11/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4889\n",
      "Epoch 12/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4545\n",
      "Epoch 13/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4499\n",
      "Epoch 14/100\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4466\n",
      "Epoch 15/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.4216\n",
      "Epoch 16/100\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.4177\n",
      "Epoch 17/100\n",
      "77/77 [==============================] - 0s 4ms/step - loss: 0.3939\n",
      "Epoch 18/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3896\n",
      "Epoch 19/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3777\n",
      "Epoch 20/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3788\n",
      "Epoch 21/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3738\n",
      "Epoch 22/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3682\n",
      "Epoch 23/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3548\n",
      "Epoch 24/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3526\n",
      "Epoch 25/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3522\n",
      "Epoch 26/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3531\n",
      "Epoch 27/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3426\n",
      "Epoch 28/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3383\n",
      "Epoch 29/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3441\n",
      "Epoch 30/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3418\n",
      "Epoch 31/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3369\n",
      "Epoch 32/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3407\n",
      "Epoch 33/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3412\n",
      "Epoch 34/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3327\n",
      "Epoch 35/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3346\n",
      "Epoch 36/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3335\n",
      "Epoch 37/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3277\n",
      "Epoch 38/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3326\n",
      "Epoch 39/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3268\n",
      "Epoch 40/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3168\n",
      "Epoch 41/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3218\n",
      "Epoch 42/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3198\n",
      "Epoch 43/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3290\n",
      "Epoch 44/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3311\n",
      "Epoch 45/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3240\n",
      "Epoch 46/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3235\n",
      "Epoch 47/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3205\n",
      "Epoch 48/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3127\n",
      "Epoch 49/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3260\n",
      "Epoch 50/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3248\n",
      "Epoch 51/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3254\n",
      "Epoch 52/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3195\n",
      "Epoch 53/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3152\n",
      "Epoch 54/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3139\n",
      "Epoch 55/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3137\n",
      "Epoch 56/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3131\n",
      "Epoch 57/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3271\n",
      "Epoch 58/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3099\n",
      "Epoch 59/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3167\n",
      "Epoch 60/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3184\n",
      "Epoch 61/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3151\n",
      "Epoch 62/100\n",
      "77/77 [==============================] - 0s 6ms/step - loss: 0.3090\n",
      "Epoch 63/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3167\n",
      "Epoch 64/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3150\n",
      "Epoch 65/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3163\n",
      "Epoch 66/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3077\n",
      "Epoch 67/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3086\n",
      "Epoch 68/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3081\n",
      "Epoch 69/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3081\n",
      "Epoch 70/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3188\n",
      "Epoch 71/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3169\n",
      "Epoch 72/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3116\n",
      "Epoch 73/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3139\n",
      "Epoch 74/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3125\n",
      "Epoch 75/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3080\n",
      "Epoch 76/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3182\n",
      "Epoch 77/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3148\n",
      "Epoch 78/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3105\n",
      "Epoch 79/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3146\n",
      "Epoch 80/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3084\n",
      "Epoch 81/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3119\n",
      "Epoch 82/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3108\n",
      "Epoch 83/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3090\n",
      "Epoch 84/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3096\n",
      "Epoch 85/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3130\n",
      "Epoch 86/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3068\n",
      "Epoch 87/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3134\n",
      "Epoch 88/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3167\n",
      "Epoch 89/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3153\n",
      "Epoch 90/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3070\n",
      "Epoch 91/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3105\n",
      "Epoch 92/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3099\n",
      "Epoch 93/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3116\n",
      "Epoch 94/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3056\n",
      "Epoch 95/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3068\n",
      "Epoch 96/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3057\n",
      "Epoch 97/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3058\n",
      "Epoch 98/100\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3037\n",
      "Epoch 99/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2996\n",
      "Epoch 100/100\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.3050\n",
      "Dropout: 0.500\n",
      "-- Training loss: 0.533\n",
      "-- Validation loss: 0.567\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    initializer = tf.keras.initializers.RandomUniform(minval=-1., maxval=1.)\n",
    "    model.add(layers.Dense(273,use_bias=True, kernel_initializer=initializer))\n",
    "    model.add(layers.Dropout(0.1))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "kr = KerasRegressor(build_fn=build_model,epochs=100,batch_size=100)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('nn', kr)\n",
    "])\n",
    "pipeline.fit(df_train, y_train)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2))\n",
    "print('Dropout: %2.3f' % dropout)\n",
    "print('-- Training loss: %2.3f' % rms(y_train- pipeline.predict(df_train)))\n",
    "print('-- Validation loss: %2.3f' % rms(y_val- pipeline.predict(df_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/4205123862.py:6: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_31/dense_84/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_31/dense_84/embedding_lookup_sparse/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_31/dense_84/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 1s 1ms/step - loss: 19.6442\n",
      "Epoch 2/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 16.6070\n",
      "Epoch 3/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 13.9687\n",
      "Epoch 4/150\n",
      "77/77 [==============================] - 0s 988us/step - loss: 11.6995\n",
      "Epoch 5/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 9.7638\n",
      "Epoch 6/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 8.1270\n",
      "Epoch 7/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 6.7538\n",
      "Epoch 8/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 5.6118\n",
      "Epoch 9/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 4.6725\n",
      "Epoch 10/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 3.9053\n",
      "Epoch 11/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 3.2829\n",
      "Epoch 12/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 2.7826\n",
      "Epoch 13/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 2.3818\n",
      "Epoch 14/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 2.0611\n",
      "Epoch 15/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.8048\n",
      "Epoch 16/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.5983\n",
      "Epoch 17/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.4313\n",
      "Epoch 18/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.2941\n",
      "Epoch 19/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.1799\n",
      "Epoch 20/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.0837\n",
      "Epoch 21/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.0010\n",
      "Epoch 22/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.9291\n",
      "Epoch 23/150\n",
      "77/77 [==============================] - 0s 921us/step - loss: 0.8654\n",
      "Epoch 24/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8088\n",
      "Epoch 25/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7579\n",
      "Epoch 26/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.7116\n",
      "Epoch 27/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6697\n",
      "Epoch 28/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.6316\n",
      "Epoch 29/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5969\n",
      "Epoch 30/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5651\n",
      "Epoch 31/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5362\n",
      "Epoch 32/150\n",
      "77/77 [==============================] - 0s 990us/step - loss: 0.5098\n",
      "Epoch 33/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4859\n",
      "Epoch 34/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4641\n",
      "Epoch 35/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4444\n",
      "Epoch 36/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4266\n",
      "Epoch 37/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4105\n",
      "Epoch 38/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3961\n",
      "Epoch 39/150\n",
      "77/77 [==============================] - 0s 984us/step - loss: 0.3830\n",
      "Epoch 40/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3713\n",
      "Epoch 41/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3609\n",
      "Epoch 42/150\n",
      "77/77 [==============================] - 0s 993us/step - loss: 0.3515\n",
      "Epoch 43/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3432\n",
      "Epoch 44/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3358\n",
      "Epoch 45/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3292\n",
      "Epoch 46/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3235\n",
      "Epoch 47/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3184\n",
      "Epoch 48/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3139\n",
      "Epoch 49/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3100\n",
      "Epoch 50/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3064\n",
      "Epoch 51/150\n",
      "77/77 [==============================] - 0s 881us/step - loss: 0.3034\n",
      "Epoch 52/150\n",
      "77/77 [==============================] - 0s 993us/step - loss: 0.3008\n",
      "Epoch 53/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2984\n",
      "Epoch 54/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2963\n",
      "Epoch 55/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2946\n",
      "Epoch 56/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2930\n",
      "Epoch 57/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2916\n",
      "Epoch 58/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2904\n",
      "Epoch 59/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2893\n",
      "Epoch 60/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2884\n",
      "Epoch 61/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2875\n",
      "Epoch 62/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2867\n",
      "Epoch 63/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2860\n",
      "Epoch 64/150\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.2854\n",
      "Epoch 65/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2849\n",
      "Epoch 66/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2843\n",
      "Epoch 67/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2839\n",
      "Epoch 68/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2834\n",
      "Epoch 69/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2830\n",
      "Epoch 70/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2826\n",
      "Epoch 71/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2823\n",
      "Epoch 72/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2819\n",
      "Epoch 73/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2816\n",
      "Epoch 74/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2814\n",
      "Epoch 75/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2811\n",
      "Epoch 76/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2809\n",
      "Epoch 77/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2806\n",
      "Epoch 78/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2804\n",
      "Epoch 79/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2803\n",
      "Epoch 80/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2801\n",
      "Epoch 81/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2798\n",
      "Epoch 82/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2797\n",
      "Epoch 83/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2795\n",
      "Epoch 84/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2793\n",
      "Epoch 85/150\n",
      "77/77 [==============================] - 0s 956us/step - loss: 0.2792\n",
      "Epoch 86/150\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.2791\n",
      "Epoch 87/150\n",
      "77/77 [==============================] - 0s 904us/step - loss: 0.2790\n",
      "Epoch 88/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2787\n",
      "Epoch 89/150\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2786\n",
      "Epoch 90/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2785\n",
      "Epoch 91/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2784\n",
      "Epoch 92/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2784\n",
      "Epoch 93/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2782\n",
      "Epoch 94/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2782\n",
      "Epoch 95/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2780\n",
      "Epoch 96/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2779\n",
      "Epoch 97/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2778\n",
      "Epoch 98/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2777\n",
      "Epoch 99/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2777\n",
      "Epoch 100/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2776\n",
      "Epoch 101/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2775\n",
      "Epoch 102/150\n",
      "77/77 [==============================] - 0s 956us/step - loss: 0.2775\n",
      "Epoch 103/150\n",
      "77/77 [==============================] - 0s 897us/step - loss: 0.2773\n",
      "Epoch 104/150\n",
      "77/77 [==============================] - 0s 846us/step - loss: 0.2773\n",
      "Epoch 105/150\n",
      "77/77 [==============================] - 0s 765us/step - loss: 0.2772\n",
      "Epoch 106/150\n",
      "77/77 [==============================] - 0s 887us/step - loss: 0.2772\n",
      "Epoch 107/150\n",
      "77/77 [==============================] - 0s 869us/step - loss: 0.2771\n",
      "Epoch 108/150\n",
      "77/77 [==============================] - 0s 878us/step - loss: 0.2770\n",
      "Epoch 109/150\n",
      "77/77 [==============================] - 0s 841us/step - loss: 0.2771\n",
      "Epoch 110/150\n",
      "77/77 [==============================] - 0s 872us/step - loss: 0.2770\n",
      "Epoch 111/150\n",
      "77/77 [==============================] - 0s 849us/step - loss: 0.2770\n",
      "Epoch 112/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2767\n",
      "Epoch 113/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2767\n",
      "Epoch 114/150\n",
      "77/77 [==============================] - 0s 984us/step - loss: 0.2767\n",
      "Epoch 115/150\n",
      "77/77 [==============================] - 0s 868us/step - loss: 0.2766\n",
      "Epoch 116/150\n",
      "77/77 [==============================] - 0s 886us/step - loss: 0.2767\n",
      "Epoch 117/150\n",
      "77/77 [==============================] - 0s 837us/step - loss: 0.2767\n",
      "Epoch 118/150\n",
      "77/77 [==============================] - 0s 879us/step - loss: 0.2765\n",
      "Epoch 119/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2765\n",
      "Epoch 120/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2764\n",
      "Epoch 121/150\n",
      "77/77 [==============================] - 0s 977us/step - loss: 0.2764\n",
      "Epoch 122/150\n",
      "77/77 [==============================] - 0s 977us/step - loss: 0.2762\n",
      "Epoch 123/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2764\n",
      "Epoch 124/150\n",
      "77/77 [==============================] - 0s 926us/step - loss: 0.2764\n",
      "Epoch 125/150\n",
      "77/77 [==============================] - 0s 930us/step - loss: 0.2763\n",
      "Epoch 126/150\n",
      "77/77 [==============================] - 0s 940us/step - loss: 0.2762\n",
      "Epoch 127/150\n",
      "77/77 [==============================] - 0s 901us/step - loss: 0.2761\n",
      "Epoch 128/150\n",
      "77/77 [==============================] - 0s 952us/step - loss: 0.2761\n",
      "Epoch 129/150\n",
      "77/77 [==============================] - 0s 890us/step - loss: 0.2761\n",
      "Epoch 130/150\n",
      "77/77 [==============================] - 0s 849us/step - loss: 0.2760\n",
      "Epoch 131/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2761\n",
      "Epoch 132/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2760\n",
      "Epoch 133/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2760\n",
      "Epoch 134/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2758\n",
      "Epoch 135/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2758\n",
      "Epoch 136/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2759\n",
      "Epoch 137/150\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2758\n",
      "Epoch 138/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2757\n",
      "Epoch 139/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2758\n",
      "Epoch 140/150\n",
      "77/77 [==============================] - 0s 952us/step - loss: 0.2756\n",
      "Epoch 141/150\n",
      "77/77 [==============================] - 0s 917us/step - loss: 0.2758\n",
      "Epoch 142/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2757\n",
      "Epoch 143/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2757\n",
      "Epoch 144/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2756\n",
      "Epoch 145/150\n",
      "77/77 [==============================] - 0s 988us/step - loss: 0.2756\n",
      "Epoch 146/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2755\n",
      "Epoch 147/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2756\n",
      "Epoch 148/150\n",
      "77/77 [==============================] - 0s 999us/step - loss: 0.2755\n",
      "Epoch 149/150\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2755\n",
      "Epoch 150/150\n",
      "77/77 [==============================] - 0s 991us/step - loss: 0.2754\n",
      "-- Training loss: 0.524\n",
      "-- Validation loss: 0.559\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(1,use_bias=True))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('nn', kr)\n",
    "])\n",
    "pipeline.fit(df_train, y_train)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2))\n",
    "print('-- Training loss: %2.3f' % rms(y_train- pipeline.predict(df_train)))\n",
    "print('-- Validation loss: %2.3f' % rms(y_val- pipeline.predict(df_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/1292449798.py:6: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=200,batch_size=100)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_32/dense_85/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_32/dense_85/embedding_lookup_sparse/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_32/dense_85/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 0s 929us/step - loss: 19.5303\n",
      "Epoch 2/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 17.3175\n",
      "Epoch 3/200\n",
      "77/77 [==============================] - 0s 983us/step - loss: 15.2993\n",
      "Epoch 4/200\n",
      "77/77 [==============================] - 0s 929us/step - loss: 13.4647\n",
      "Epoch 5/200\n",
      "77/77 [==============================] - 0s 968us/step - loss: 11.8153\n",
      "Epoch 6/200\n",
      "77/77 [==============================] - 0s 996us/step - loss: 10.3178\n",
      "Epoch 7/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 8.9647\n",
      "Epoch 8/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 7.7444\n",
      "Epoch 9/200\n",
      "77/77 [==============================] - 0s 961us/step - loss: 6.6579\n",
      "Epoch 10/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 5.7006\n",
      "Epoch 11/200\n",
      "77/77 [==============================] - 0s 996us/step - loss: 4.8678\n",
      "Epoch 12/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 4.1579\n",
      "Epoch 13/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 3.5568\n",
      "Epoch 14/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 3.0491\n",
      "Epoch 15/200\n",
      "77/77 [==============================] - 0s 982us/step - loss: 2.6256\n",
      "Epoch 16/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 2.2730\n",
      "Epoch 17/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.9818\n",
      "Epoch 18/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.7414\n",
      "Epoch 19/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.5435\n",
      "Epoch 20/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.3791\n",
      "Epoch 21/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.2411\n",
      "Epoch 22/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 1.1252\n",
      "Epoch 23/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 1.0293\n",
      "Epoch 24/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.9477\n",
      "Epoch 25/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8781\n",
      "Epoch 26/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.8175\n",
      "Epoch 27/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.7644\n",
      "Epoch 28/200\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.7168\n",
      "Epoch 29/200\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.6743\n",
      "Epoch 30/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6353\n",
      "Epoch 31/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.6001\n",
      "Epoch 32/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5680\n",
      "Epoch 33/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.5404\n",
      "Epoch 34/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.5158\n",
      "Epoch 35/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4934\n",
      "Epoch 36/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4727\n",
      "Epoch 37/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4537\n",
      "Epoch 38/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4367\n",
      "Epoch 39/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4217\n",
      "Epoch 40/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.4084\n",
      "Epoch 41/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3965\n",
      "Epoch 42/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3857\n",
      "Epoch 43/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3761\n",
      "Epoch 44/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3674\n",
      "Epoch 45/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3598\n",
      "Epoch 46/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3534\n",
      "Epoch 47/200\n",
      "77/77 [==============================] - 0s 974us/step - loss: 0.3477\n",
      "Epoch 48/200\n",
      "77/77 [==============================] - 0s 922us/step - loss: 0.3426\n",
      "Epoch 49/200\n",
      "77/77 [==============================] - 0s 953us/step - loss: 0.3378\n",
      "Epoch 50/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3336\n",
      "Epoch 51/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3296\n",
      "Epoch 52/200\n",
      "77/77 [==============================] - 0s 976us/step - loss: 0.3261\n",
      "Epoch 53/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3228\n",
      "Epoch 54/200\n",
      "77/77 [==============================] - 0s 981us/step - loss: 0.3200\n",
      "Epoch 55/200\n",
      "77/77 [==============================] - 0s 939us/step - loss: 0.3174\n",
      "Epoch 56/200\n",
      "77/77 [==============================] - 0s 966us/step - loss: 0.3151\n",
      "Epoch 57/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3130\n",
      "Epoch 58/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3112\n",
      "Epoch 59/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3097\n",
      "Epoch 60/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3085\n",
      "Epoch 61/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3072\n",
      "Epoch 62/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3061\n",
      "Epoch 63/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3051\n",
      "Epoch 64/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3041\n",
      "Epoch 65/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3032\n",
      "Epoch 66/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3024\n",
      "Epoch 67/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3017\n",
      "Epoch 68/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.3009\n",
      "Epoch 69/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.3002\n",
      "Epoch 70/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2997\n",
      "Epoch 71/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2992\n",
      "Epoch 72/200\n",
      "77/77 [==============================] - 0s 993us/step - loss: 0.2986\n",
      "Epoch 73/200\n",
      "77/77 [==============================] - 0s 999us/step - loss: 0.2981\n",
      "Epoch 74/200\n",
      "77/77 [==============================] - 0s 985us/step - loss: 0.2978\n",
      "Epoch 75/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2973\n",
      "Epoch 76/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2969\n",
      "Epoch 77/200\n",
      "77/77 [==============================] - 0s 957us/step - loss: 0.2965\n",
      "Epoch 78/200\n",
      "77/77 [==============================] - 0s 956us/step - loss: 0.2962\n",
      "Epoch 79/200\n",
      "77/77 [==============================] - 0s 968us/step - loss: 0.2958\n",
      "Epoch 80/200\n",
      "77/77 [==============================] - 0s 911us/step - loss: 0.2956\n",
      "Epoch 81/200\n",
      "77/77 [==============================] - 0s 877us/step - loss: 0.2952\n",
      "Epoch 82/200\n",
      "77/77 [==============================] - 0s 863us/step - loss: 0.2950\n",
      "Epoch 83/200\n",
      "77/77 [==============================] - 0s 868us/step - loss: 0.2947\n",
      "Epoch 84/200\n",
      "77/77 [==============================] - 0s 844us/step - loss: 0.2944\n",
      "Epoch 85/200\n",
      "77/77 [==============================] - 0s 890us/step - loss: 0.2942\n",
      "Epoch 86/200\n",
      "77/77 [==============================] - 0s 860us/step - loss: 0.2940\n",
      "Epoch 87/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2937\n",
      "Epoch 88/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2934\n",
      "Epoch 89/200\n",
      "77/77 [==============================] - 0s 980us/step - loss: 0.2933\n",
      "Epoch 90/200\n",
      "77/77 [==============================] - 0s 966us/step - loss: 0.2931\n",
      "Epoch 91/200\n",
      "77/77 [==============================] - 0s 984us/step - loss: 0.2929\n",
      "Epoch 92/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2927\n",
      "Epoch 93/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2924\n",
      "Epoch 94/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2923\n",
      "Epoch 95/200\n",
      "77/77 [==============================] - 0s 986us/step - loss: 0.2921\n",
      "Epoch 96/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2919\n",
      "Epoch 97/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2918\n",
      "Epoch 98/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2916\n",
      "Epoch 99/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2915\n",
      "Epoch 100/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2913\n",
      "Epoch 101/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2911\n",
      "Epoch 102/200\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.2910\n",
      "Epoch 103/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2909\n",
      "Epoch 104/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2907\n",
      "Epoch 105/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2906\n",
      "Epoch 106/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2905\n",
      "Epoch 107/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2904\n",
      "Epoch 108/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2902\n",
      "Epoch 109/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2901\n",
      "Epoch 110/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2900\n",
      "Epoch 111/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2898\n",
      "Epoch 112/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2897\n",
      "Epoch 113/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2896\n",
      "Epoch 114/200\n",
      "77/77 [==============================] - 0s 3ms/step - loss: 0.2895\n",
      "Epoch 115/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2894\n",
      "Epoch 116/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2893\n",
      "Epoch 117/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2892\n",
      "Epoch 118/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2891\n",
      "Epoch 119/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2891\n",
      "Epoch 120/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2890\n",
      "Epoch 121/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2888\n",
      "Epoch 122/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2888\n",
      "Epoch 123/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2887\n",
      "Epoch 124/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2886\n",
      "Epoch 125/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2885\n",
      "Epoch 126/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2885\n",
      "Epoch 127/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2883\n",
      "Epoch 128/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2883\n",
      "Epoch 129/200\n",
      "77/77 [==============================] - 0s 956us/step - loss: 0.2881\n",
      "Epoch 130/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2881\n",
      "Epoch 131/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2880\n",
      "Epoch 132/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2879\n",
      "Epoch 133/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2878\n",
      "Epoch 134/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2877\n",
      "Epoch 135/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2877\n",
      "Epoch 136/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2876\n",
      "Epoch 137/200\n",
      "77/77 [==============================] - 0s 2ms/step - loss: 0.2875\n",
      "Epoch 138/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2875\n",
      "Epoch 139/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2874\n",
      "Epoch 140/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2873\n",
      "Epoch 141/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2873\n",
      "Epoch 142/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2872\n",
      "Epoch 143/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2871\n",
      "Epoch 144/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2871\n",
      "Epoch 145/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2870\n",
      "Epoch 146/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2869\n",
      "Epoch 147/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2868\n",
      "Epoch 148/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2868\n",
      "Epoch 149/200\n",
      "77/77 [==============================] - 0s 975us/step - loss: 0.2868\n",
      "Epoch 150/200\n",
      "77/77 [==============================] - 0s 955us/step - loss: 0.2867\n",
      "Epoch 151/200\n",
      "77/77 [==============================] - 0s 988us/step - loss: 0.2866\n",
      "Epoch 152/200\n",
      "77/77 [==============================] - 0s 995us/step - loss: 0.2866\n",
      "Epoch 153/200\n",
      "77/77 [==============================] - 0s 994us/step - loss: 0.2865\n",
      "Epoch 154/200\n",
      "77/77 [==============================] - 0s 981us/step - loss: 0.2865\n",
      "Epoch 155/200\n",
      "77/77 [==============================] - 0s 977us/step - loss: 0.2864\n",
      "Epoch 156/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2864\n",
      "Epoch 157/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2863\n",
      "Epoch 158/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2862\n",
      "Epoch 159/200\n",
      "77/77 [==============================] - 0s 999us/step - loss: 0.2862\n",
      "Epoch 160/200\n",
      "77/77 [==============================] - 0s 970us/step - loss: 0.2861\n",
      "Epoch 161/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2861\n",
      "Epoch 162/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2860\n",
      "Epoch 163/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2860\n",
      "Epoch 164/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2859\n",
      "Epoch 165/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2859\n",
      "Epoch 166/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2858\n",
      "Epoch 167/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2858\n",
      "Epoch 168/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2857\n",
      "Epoch 169/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2857\n",
      "Epoch 170/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2856\n",
      "Epoch 171/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2856\n",
      "Epoch 172/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2855\n",
      "Epoch 173/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2855\n",
      "Epoch 174/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2855\n",
      "Epoch 175/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2854\n",
      "Epoch 176/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2854\n",
      "Epoch 177/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2854\n",
      "Epoch 178/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2853\n",
      "Epoch 179/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2852\n",
      "Epoch 180/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2852\n",
      "Epoch 181/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2851\n",
      "Epoch 182/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2851\n",
      "Epoch 183/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2851\n",
      "Epoch 184/200\n",
      "77/77 [==============================] - 0s 995us/step - loss: 0.2850\n",
      "Epoch 185/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2850\n",
      "Epoch 186/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2850\n",
      "Epoch 187/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2849\n",
      "Epoch 188/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2849\n",
      "Epoch 189/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2849\n",
      "Epoch 190/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2848\n",
      "Epoch 191/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2847\n",
      "Epoch 192/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2847\n",
      "Epoch 193/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2847\n",
      "Epoch 194/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2846\n",
      "Epoch 195/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2846\n",
      "Epoch 196/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2846\n",
      "Epoch 197/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2845\n",
      "Epoch 198/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2845\n",
      "Epoch 199/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2845\n",
      "Epoch 200/200\n",
      "77/77 [==============================] - 0s 1ms/step - loss: 0.2844\n",
      "-- Training loss: 0.533\n",
      "-- Validation loss: 0.553\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(1,use_bias=True))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adamax')\n",
    "    return model\n",
    "kr = KerasRegressor(build_fn=build_model,epochs=200,batch_size=100)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('nn', kr)\n",
    "])\n",
    "pipeline.fit(df_train, y_train)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2))\n",
    "print('-- Training loss: %2.3f' % rms(y_train- pipeline.predict(df_train)))\n",
    "print('-- Validation loss: %2.3f' % rms(y_val- pipeline.predict(df_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adamax with different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/1552145588.py:8: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_33/dense_86/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_33/dense_86/embedding_lookup_sparse/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_33/dense_86/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 1.000e-04\n",
      "-- Training loss: 1.442\n",
      "-- Validation loss: 1.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/1552145588.py:8: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_34/dense_87/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_34/dense_87/embedding_lookup_sparse/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_34/dense_87/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.000e-04\n",
      "-- Training loss: 0.541\n",
      "-- Validation loss: 0.554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/1552145588.py:8: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_35/dense_88/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_35/dense_88/embedding_lookup_sparse/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_35/dense_88/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 1.000e-03\n",
      "-- Training loss: 0.535\n",
      "-- Validation loss: 0.551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/1552145588.py:8: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_36/dense_89/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_36/dense_89/embedding_lookup_sparse/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_36/dense_89/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 2.000e-03\n",
      "-- Training loss: 0.531\n",
      "-- Validation loss: 0.553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/1552145588.py:8: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.000e-03\n",
      "-- Training loss: 0.528\n",
      "-- Validation loss: 0.555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_37/dense_90/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_37/dense_90/embedding_lookup_sparse/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_37/dense_90/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/1552145588.py:8: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_38/dense_91/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_38/dense_91/embedding_lookup_sparse/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_38/dense_91/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 1.000e-02\n",
      "-- Training loss: 0.525\n",
      "-- Validation loss: 0.558\n"
     ]
    }
   ],
   "source": [
    "for lr in [1e-4,5e-4,1e-3,2e-3,5e-3,1e-2]:\n",
    "    def build_model():\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Dense(1,use_bias=True))\n",
    "        opt = keras.optimizers.Adamax(learning_rate = lr)\n",
    "        model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "        return model\n",
    "    kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('transformer', transf),\n",
    "        ('nn', kr)\n",
    "    ])\n",
    "    pipeline.fit(df_train, y_train)\n",
    "\n",
    "    def rms(x):\n",
    "        return np.sqrt(np.mean(x**2))\n",
    "    print('lr: %2.3e' % lr)\n",
    "    print('-- Training loss: %2.3f' % rms(y_train- pipeline.predict(df_train)))\n",
    "    print('-- Validation loss: %2.3f' % rms(y_val- pipeline.predict(df_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adam with different learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/1025543893.py:8: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_39/dense_92/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_39/dense_92/embedding_lookup_sparse/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_39/dense_92/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 1.000e-04\n",
      "-- Training loss: 0.989\n",
      "-- Validation loss: 0.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/1025543893.py:8: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_40/dense_93/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_40/dense_93/embedding_lookup_sparse/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_40/dense_93/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.000e-04\n",
      "-- Training loss: 0.528\n",
      "-- Validation loss: 0.556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/1025543893.py:8: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_41/dense_94/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_41/dense_94/embedding_lookup_sparse/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_41/dense_94/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 1.000e-03\n",
      "-- Training loss: 0.524\n",
      "-- Validation loss: 0.559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/1025543893.py:8: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_42/dense_95/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_42/dense_95/embedding_lookup_sparse/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_42/dense_95/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 2.000e-03\n",
      "-- Training loss: 0.523\n",
      "-- Validation loss: 0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/1025543893.py:8: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_43/dense_96/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_43/dense_96/embedding_lookup_sparse/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_43/dense_96/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 5.000e-03\n",
      "-- Training loss: 0.525\n",
      "-- Validation loss: 0.563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/1025543893.py:8: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_44/dense_97/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_44/dense_97/embedding_lookup_sparse/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_44/dense_97/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 1.000e-02\n",
      "-- Training loss: 0.524\n",
      "-- Validation loss: 0.562\n"
     ]
    }
   ],
   "source": [
    "for lr in [1e-4,5e-4,1e-3,2e-3,5e-3,1e-2]:\n",
    "    def build_model():\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Dense(1,use_bias=True))\n",
    "        opt = keras.optimizers.Adam(learning_rate = lr)\n",
    "        model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "        return model\n",
    "    kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('transformer', transf),\n",
    "        ('nn', kr)\n",
    "    ])\n",
    "    pipeline.fit(df_train, y_train)\n",
    "\n",
    "    def rms(x):\n",
    "        return np.sqrt(np.mean(x**2))\n",
    "    print('lr: %2.3e' % lr)\n",
    "    print('-- Training loss: %2.3f' % rms(y_train- pipeline.predict(df_train)))\n",
    "    print('-- Validation loss: %2.3f' % rms(y_val- pipeline.predict(df_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/112345705.py:7: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_46/dense_99/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_46/dense_99/embedding_lookup_sparse/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_46/dense_99/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 1.000e-02\n",
      "-- Training loss: 0.528\n",
      "-- Validation loss: 0.553\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(1,use_bias=True))\n",
    "    opt = keras.optimizers.RMSprop()\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    return model\n",
    "kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('nn', kr)\n",
    "])\n",
    "pipeline.fit(df_train, y_train)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2))\n",
    "print('lr: %2.3e' % lr)\n",
    "print('-- Training loss: %2.3f' % rms(y_train- pipeline.predict(df_train)))\n",
    "print('-- Validation loss: %2.3f' % rms(y_val- pipeline.predict(df_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trying with different optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_22192/80736350.py:9: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n",
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_51/dense_106/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_51/dense_106/embedding_lookup_sparse/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_51/dense_106/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 1.000e-02\n",
      "-- Training loss: 0.535\n",
      "-- Validation loss: 0.552\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(1,use_bias=False))\n",
    "    #opt = keras.optimizers.RMSprop()\n",
    "    #opt = keras.optimizers.Adagrad()\n",
    "    opt = keras.optimizers.SGD()\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    return model\n",
    "kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('nn', kr)\n",
    "])\n",
    "pipeline.fit(df_train, y_train)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.mean(x**2))\n",
    "print('lr: %2.3e' % lr)\n",
    "print('-- Training loss: %2.3f' % rms(y_train- pipeline.predict(df_train)))\n",
    "print('-- Validation loss: %2.3f' % rms(y_val- pipeline.predict(df_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da90f46fa8a14be9631a6692cf25b531474837a478d46ca898e64c54b1530bf9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
