{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone project, Part 3\n",
    "for Zoomcamp, Ahmed Yahia Kallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuation of the notebook, with focus on Ensemble-based and sophisticated regressors.\n",
    "\n",
    "So far, these are the best output\n",
    "* GB-lr003nest1000\n",
    "* training accuracy: 0.494942\n",
    "* validation accuracy: 0.544177"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train.py (part of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# libarires\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#splitter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "#transformers\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "\n",
    "#model\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "#save pickle\n",
    "import pickle\n",
    "\n",
    "#read database\n",
    "df = pd.read_csv(\"Property Prices in Tunisia.csv\") #load file\n",
    "\n",
    "#translation\n",
    "df.replace(df[\"category\"].unique(), ['Land and Farms', 'Apartments', 'Holiday rentals',\n",
    "       'Shops, Businesses and Industrial Premises', 'Houses and Villas',\n",
    "       'Flatshare', 'Offices and Trays'],inplace=True)\n",
    "\n",
    "df.replace(df[\"type\"].unique(), ['For sale', 'For rent'],inplace=True)\n",
    "\n",
    "df.replace(\"Autres villes\",\"Others\", inplace=True)\n",
    "\n",
    "del df[\"price\"] \n",
    "\n",
    "\n",
    "# data splitting\n",
    "\n",
    "#split according to random state = 1\n",
    "df_trainval, df_test = train_test_split(df, test_size=0.2, random_state=1) #split train+val [80%], test [20%]\n",
    "df_train, df_val = train_test_split(df_trainval, test_size=0.25, random_state=1) #split train[60%] val [20%]\n",
    "\n",
    "#reset, drop index\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "\n",
    "y_test = df_test[\"log_price\"].values\n",
    "y_train = df_train[\"log_price\"].values\n",
    "y_val = df_val[\"log_price\"].values\n",
    "\n",
    "del df_test[\"log_price\"]\n",
    "del df_train[\"log_price\"]\n",
    "del df_val[\"log_price\"]\n",
    "\n",
    "\n",
    "\n",
    "# feature types\n",
    "feat_cat = ['category','type','city','region']\n",
    "feat_num = ['room_count','bathroom_count','size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = [\n",
    "    ('Scal_num', RobustScaler(unit_variance=True) , feat_num),\n",
    "    ('categorical', OneHotEncoder(dtype=np.int32,handle_unknown = 'ignore'), feat_cat)\n",
    "]\n",
    "transf = ColumnTransformer(transformations, remainder='drop')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "libs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "#models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(v):\n",
    "    return np.sqrt(np.mean(v**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "non keras pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_linear_regression = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "\n",
    "pipeline_svr = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('svr', SVR(C=0.9,epsilon=0.15))\n",
    "])\n",
    "\n",
    "pipeline_rfr = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('rfr', RandomForestRegressor(max_depth=5, n_estimators=31))\n",
    "])\n",
    "pipeline_enet = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('en', ElasticNet(alpha=0.004, l1_ratio=0.055))\n",
    "])\n",
    "pipeline_gb = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('gb', GradientBoostingRegressor(learning_rate=0.03,n_estimators=1000 ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Temp/ipykernel_60204/841995247.py:7: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(1,use_bias=True))\n",
    "    opt = keras.optimizers.Adamax()\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "    return model\n",
    "kr = KerasRegressor(build_fn=build_model,epochs=150,batch_size=100,verbose=False)\n",
    "kr._estimator_type = \"regressor\"\n",
    "pipeline_kr = Pipeline([\n",
    "        ('transformer', transf),\n",
    "        ('nn', kr)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Voting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kay_t\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:448: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential_4/dense_4/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential_4/dense_4/embedding_lookup_sparse/Reshape:0\", shape=(None, 1), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential_4/dense_4/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy (RMSE): 0.510\n",
      "Validation accuracy (RMSE): 0.542\n"
     ]
    }
   ],
   "source": [
    "voting1 = VotingRegressor(\n",
    "             estimators=[('lr', pipeline_linear_regression),\n",
    "                         ('svr', pipeline_svr),\n",
    "                         ('rfr',pipeline_rfr),\n",
    "                         ('enet',pipeline_enet),\n",
    "                         ('gb',pipeline_gb),\n",
    "                         ('kr',pipeline_kr)])\n",
    "voting1.fit(df_train,y_train)\n",
    "y_train_hat = voting1.predict(df_train)\n",
    "y_val_hat = voting1.predict(df_val)\n",
    "print('Training accuracy (RMSE): %2.3f' % rms(y_train_hat-y_train))\n",
    "print('Validation accuracy (RMSE): %2.3f' % rms(y_val_hat-y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy (RMSE): 0.507\n",
      "Validation accuracy (RMSE): 0.541\n"
     ]
    }
   ],
   "source": [
    "voting2 = VotingRegressor(\n",
    "             estimators=[('lr', pipeline_linear_regression),\n",
    "                         ('svr', pipeline_svr),\n",
    "                         ('rfr',pipeline_rfr),\n",
    "                         ('enet',pipeline_enet),\n",
    "                         ('gb',pipeline_gb)])\n",
    "#  seems like it doesn't provide much addition\n",
    "voting2.fit(df_train,y_train)\n",
    "y_train_hat = voting2.predict(df_train)\n",
    "y_val_hat = voting2.predict(df_val)\n",
    "print('Training accuracy (RMSE): %2.3f' % rms(y_train_hat-y_train))\n",
    "print('Validation accuracy (RMSE): %2.3f' % rms(y_val_hat-y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy (RMSE): 0.495\n",
      "Validation accuracy (RMSE): 0.549\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "pipeline_adab = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('ada', AdaBoostRegressor(random_state=0, n_estimators=100,learning_rate=0.01, base_estimator=GradientBoostingRegressor(learning_rate=0.03,n_estimators=1000 )))\n",
    "])\n",
    "\n",
    "pipeline_adab.fit(df_train,y_train)\n",
    "y_train_hat = pipeline_adab.predict(df_train)\n",
    "y_val_hat = pipeline_adab.predict(df_val)\n",
    "print('Training accuracy (RMSE): %2.3f' % rms(y_train_hat-y_train))\n",
    "print('Validation accuracy (RMSE): %2.3f' % rms(y_val_hat-y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy (RMSE): 0.516\n",
      "Validation accuracy (RMSE): 0.544\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "pipeline_adab = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('ada', AdaBoostRegressor(random_state=0, n_estimators=200,learning_rate=0.0001, base_estimator=GradientBoostingRegressor( )))\n",
    "])\n",
    "\n",
    "pipeline_adab.fit(df_train,y_train)\n",
    "y_train_hat = pipeline_adab.predict(df_train)\n",
    "y_val_hat = pipeline_adab.predict(df_val)\n",
    "print('Training accuracy (RMSE): %2.3f' % rms(y_train_hat-y_train))\n",
    "print('Validation accuracy (RMSE): %2.3f' % rms(y_val_hat-y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_60204/3246797129.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m ])\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mpipeline_adab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0my_train_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline_adab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0my_val_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline_adab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1063\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m         \u001b[1;31m# Fit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1065\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0miboost\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[1;31m# Boosting step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m             sample_weight, estimator_weight, estimator_error = self._boost(\n\u001b[0m\u001b[0;32m    146\u001b[0m                 \u001b[0miboost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m             )\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[1;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[0;32m   1125\u001b[0m         \u001b[0mX_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbootstrap_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m         \u001b[0my_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbootstrap_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1127\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1128\u001b[0m         \u001b[0my_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_sparse_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_probB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_status_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibsvm_sparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlibsvm_sparse_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\svm\\_libsvm_sparse.pyx\u001b[0m in \u001b[0;36msklearn.svm._libsvm_sparse.libsvm_sparse_train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;34m\"\"\"base matrix class for compressed row- and column-oriented matrices\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0m_data_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# it took around 23 mins\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "pipeline_adab = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('ada', AdaBoostRegressor(random_state=0, n_estimators=200,learning_rate=0.0001, base_estimator=SVR( )))\n",
    "])\n",
    "\n",
    "pipeline_adab.fit(df_train,y_train)\n",
    "y_train_hat = pipeline_adab.predict(df_train)\n",
    "y_val_hat = pipeline_adab.predict(df_val)\n",
    "print('Training accuracy (RMSE): %2.3f' % rms(y_train_hat-y_train))\n",
    "print('Validation accuracy (RMSE): %2.3f' % rms(y_val_hat-y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy (RMSE): 0.513\n",
      "Validation accuracy (RMSE): 0.544\n"
     ]
    }
   ],
   "source": [
    "# it took around 23 mins\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "pipeline_br = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('br', BaggingRegressor(random_state=0, n_estimators=1000, base_estimator=GradientBoostingRegressor( )))\n",
    "])\n",
    "\n",
    "pipeline_br.fit(df_train,y_train)\n",
    "y_train_hat = pipeline_br.predict(df_train)\n",
    "y_val_hat = pipeline_br.predict(df_val)\n",
    "print('Training accuracy (RMSE): %2.3f' % rms(y_train_hat-y_train))\n",
    "print('Validation accuracy (RMSE): %2.3f' % rms(y_val_hat-y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy (RMSE): 0.372\n",
      "Validation accuracy (RMSE): 0.557\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "pipeline_etr = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('et', ExtraTreesRegressor(random_state=0, n_estimators=1000,  max_features='sqrt',n_jobs=16,warm_start=True,bootstrap=True))\n",
    "])\n",
    "\n",
    "pipeline_etr.fit(df_train,y_train)\n",
    "y_train_hat = pipeline_etr.predict(df_train)\n",
    "y_val_hat = pipeline_etr.predict(df_val)\n",
    "print('Training accuracy (RMSE): %2.3f' % rms(y_train_hat-y_train))\n",
    "print('Validation accuracy (RMSE): %2.3f' % rms(y_val_hat-y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy (RMSE): 0.422\n",
      "Validation accuracy (RMSE): 0.545\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "pipeline_etr = Pipeline([\n",
    "    ('transformer', transf),\n",
    "    ('et', ExtraTreesRegressor(random_state=0, n_estimators=1000,  max_features='auto',n_jobs=16,warm_start=True,bootstrap=True,min_samples_split=7))\n",
    "])\n",
    "\n",
    "pipeline_etr.fit(df_train,y_train)\n",
    "y_train_hat = pipeline_etr.predict(df_train)\n",
    "y_val_hat = pipeline_etr.predict(df_val)\n",
    "print('Training accuracy (RMSE): %2.3f' % rms(y_train_hat-y_train))\n",
    "print('Validation accuracy (RMSE): %2.3f' % rms(y_val_hat-y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Voting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy (RMSE): 0.491\n",
      "Validation accuracy (RMSE): 0.538\n"
     ]
    }
   ],
   "source": [
    "voting3 = VotingRegressor(\n",
    "             estimators=[('lr', pipeline_linear_regression),\n",
    "                         ('svr', pipeline_svr),\n",
    "                         ('rfr',pipeline_rfr),\n",
    "                         ('enet',pipeline_enet),\n",
    "                         ('br',pipeline_br),\n",
    "                         ('etr',pipeline_etr)])\n",
    "#  seems like it doesn't provide much addition\n",
    "voting3.fit(df_train,y_train)\n",
    "y_train_hat = voting3.predict(df_train)\n",
    "y_val_hat = voting3.predict(df_val)\n",
    "print('Training accuracy (RMSE): %2.3f' % rms(y_train_hat-y_train))\n",
    "print('Validation accuracy (RMSE): %2.3f' % rms(y_val_hat-y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pipeline_voting as best method\n",
    "with open(\"pipeline_voting.bin\", 'wb') as f:  pickle.dump(voting3,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy (RMSE): 0.481\n",
      "Validation accuracy (RMSE): 0.535\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "estimators=[('lr', pipeline_linear_regression),\n",
    "                         ('svr', pipeline_svr),\n",
    "                         ('rfr',pipeline_rfr),\n",
    "                         ('enet',pipeline_enet),\n",
    "                         ('br',pipeline_br),\n",
    "                         ('etr',pipeline_etr),\n",
    "                         ('gb',pipeline_gb)]\n",
    "\n",
    "pipeline_stack = StackingRegressor(estimators=estimators,n_jobs=16,cv=3)\n",
    "\n",
    "pipeline_stack.fit(df_train,y_train)\n",
    "y_train_hat = pipeline_stack.predict(df_train)\n",
    "y_val_hat = pipeline_stack.predict(df_val)\n",
    "print('Training accuracy (RMSE): %2.3f' % rms(y_train_hat-y_train))\n",
    "print('Validation accuracy (RMSE): %2.3f' % rms(y_val_hat-y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pipeline_stacking.bin\", 'wb') as f:  pickle.dump(pipeline_stack,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please use [extra_predictors/predict_stacking.py](extra_predictors/predict_stacking.py) or [extra_predictors/predict_voting.py](extra_predictors/predict_voting.py)  for fast-testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       category  room_count  bathroom_count   size      type    city  region\n",
      "201  Apartments         2.0             1.0  110.0  For sale  Mahdia  Mahdia\n",
      "Price for ID 201 : ~187029 TND [log_price: 5.272]\n"
     ]
    }
   ],
   "source": [
    "# client.py: get data of the new user\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "id =201 #select here an id to test!\n",
    "example = df_test.iloc[id:id+1,:].to_json()\n",
    "expected_res = y_test[id]\n",
    "\n",
    "\n",
    "\n",
    "url = \"http://127.0.0.1:9696/predict\"\n",
    "results = requests.post(url, json=example).json()\n",
    "print(df_test.iloc[id:id+1,:])\n",
    "log_price = results[\"log_price\"]\n",
    "\n",
    "\n",
    "print(\"Price for ID %d : ~%d TND [log_price: %2.3f]\" % (id, 10**log_price, log_price))\n",
    "#print(\"actual price: %d TND [log_price: %2.3f]\" % (10**expected_res,expected_res))\n",
    "\n",
    "\n",
    "# rounded\n",
    "#print(\"Price for ID %d : ~%d TND [log_price: %2.3f]\" % (id, 10**round(log_price,1), round(log_price,1)))\n",
    "#print(\"actual price: %d TND [log_price: %2.3f]\" % (10**round(expected_res,1),round(expected_res,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da90f46fa8a14be9631a6692cf25b531474837a478d46ca898e64c54b1530bf9"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
